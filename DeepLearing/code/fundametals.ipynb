{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d77cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93c67b",
   "metadata": {},
   "source": [
    "# Q1. Implement a single neuron (no frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886ac50",
   "metadata": {},
   "source": [
    "* In single nuron is combination of weight sum function and top of that apply's a activation function.\n",
    "\n",
    "- let's suppose input x = 5, w =0.5, bias = 0.2\n",
    "- sigmoid = 1/1-exp ^(-z)\n",
    "\n",
    "-  y = sigmoid(0.5 * 5 + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3572246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0672055127397497)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def nuron(w : float, x: float, b: float)-> float:\n",
    "\tweight_sum = w*x + b\n",
    "\n",
    "\ty = 1/ 1+ np.exp(-weight_sum)\n",
    "\treturn y\n",
    "\n",
    "nuron(x=5,w=0.5,b=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf6715",
   "metadata": {},
   "source": [
    "# Q2. Implement softmax safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e510b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. input 2 -> Expotial 7.38905609893065\n",
      "1. input 1 -> Expotial 2.718281828459045\n",
      "2. input 0.1 -> Expotial 1.1051709180756477\n",
      "3. input -1 -> Expotial 0.36787944117144233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(0.6380663511479375),\n",
       " np.float64(0.23473149269060453),\n",
       " np.float64(0.09543470311362202),\n",
       " np.float64(0.03176745304783585)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(vector:list)->list:\n",
    "\t# compute expontial for each data\n",
    "\texpontial = []\n",
    "\tfor i, data in enumerate(vector):\n",
    "\t\tresult = np.exp(data)\n",
    "\t\tprint(f\"{i}. input {data} -> Expotial {result}\")\n",
    "\t\texpontial.append(result)\n",
    "\ttotal_expotial = np.sum(expontial)\n",
    "\n",
    "\tprobability = [data/total_expotial for data in expontial]\n",
    "\n",
    "\treturn probability\n",
    "\n",
    "softmax([2,1,0.1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e04b3e",
   "metadata": {},
   "source": [
    "# Q3. Implement ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fe8129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.2, 0, 0, 2.8, 0, 1.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(vector:list)->list:\n",
    "\tresult = []\n",
    "\tfor i, data in enumerate(vector):\n",
    "\t\tif data <=0:\n",
    "\t\t\tdata =0\n",
    "\t\t\tresult.append(data)\n",
    "\t\telse:\n",
    "\t\t\tresult.append(data)\n",
    "\treturn result\n",
    "\n",
    "relu([3.2, -1.5, 0.0, 2.8, -4.1, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a65bb",
   "metadata": {},
   "source": [
    "# Q4. Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ef1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "\tresult =- y_true * np.log(y_pred) + (1- y_true)*np.log(1-y_pred)\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "174bc330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.05129329438755058)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cross_entropy(1,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17dd26",
   "metadata": {},
   "source": [
    "# Q5. Forward Pass of Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01f3bedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  w[0] * x[0] = 0.5 * 0.5 = 1000.0\n",
      "  w[1] * x[1] = -100 * -100 = -500\n",
      "  w[2] * x[2] = 5000 * 5000 = 15000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65500.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_pass(weight, x, bias):\n",
    "\tresult = 0\n",
    "\tfor i,data in enumerate(weight):\n",
    "\t\tz = weight[i]*x[i] \n",
    "\t\tprint(f\"  w[{i}] * x[{i}] = {w[i]} * {x[i]} = {z}\")\n",
    "\t\tresult += z\n",
    "\n",
    "\treturn result + bias\n",
    "\n",
    "x = [2000, 5, 3]           # [square footage, age, bedrooms]\n",
    "w = [0.5, -100, 5000]      # weights\n",
    "b = 50000                  # bias\n",
    "\n",
    "forward_pass(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0ed0872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  w[0] * x[0] = 0.5 * 2000 = 1000.0\n",
      "  w[1] * x[1] = -100 * 5 = -500\n",
      "  w[2] * x[2] = 5000 * 3 = 15000\n",
      "  w[0] * x[0] = 0.5 * 1500 = 750.0\n",
      "  w[1] * x[1] = -100 * 3 = -300\n",
      "  w[2] * x[2] = 5000 * 2 = 10000\n",
      "  w[0] * x[0] = 0.5 * 3000 = 1500.0\n",
      "  w[1] * x[1] = -100 * 10 = -1000\n",
      "  w[2] * x[2] = 5000 * 4 = 20000\n"
     ]
    }
   ],
   "source": [
    "inputs = [[2000, 5, 3],      # House 1\n",
    "\t\t\t[1500, 3, 2],      # House 2\n",
    "\t\t\t[3000, 10, 4]]\n",
    "\n",
    "weights = [[0.5, 0.2, 0.3],\n",
    "\t\t\t[0.4, 0.3, 0.2],\n",
    "\t\t\t[0.1, 0.1, 0.1]]\n",
    "\n",
    "bias  = [1,1,1]\n",
    "result = [forward_pass(weight=w, bias=bias[i], x=inputs[i]) for i in range(len(inputs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6defdb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f06a23",
   "metadata": {},
   "source": [
    "# Q5 Compute Gradients for MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7e27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
